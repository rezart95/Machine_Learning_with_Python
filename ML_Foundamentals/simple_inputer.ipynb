{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Imputer\n",
    "Learning Objectives\n",
    "By the end of this module, you should be able to:\n",
    "Explain why Simple Imputer prevents data leakage\n",
    "Use SimpleImputer to impute missing values \n",
    "Use ColumnTransformer to perform different imputation strategies on different columns\n",
    "SimpleImputer Prevents Data Leakage\n",
    "We have learned that missing values must be addressed as an essential component of data cleaning for analytics.  Missing values must also be addressed as part of data pre-processing required for machine learning.  \n",
    "Now that we intend to use our data for machine learning, we must be very careful to prevent data leakage.  This means we do not impute values based on any calculations that involve the test set. \n",
    "Any calculations (such as mean, median, or even most frequent) must be done using only the training set to avoid data leakage.  We impute AFTER our validation split.\n",
    "Sklearn's SimpleImputer allows us to perform calculations on the training data and then apply those calculations to both the training data and the test data in just a few lines of code.  \n",
    "\n",
    "Imputation Strategies\n",
    "Simple imputer can use any of 5 strategies to impute values:\n",
    " 'mean', fill missing values with the mean of the column they are in.\n",
    "'median', fill missing values with the median of the column they are in.\n",
    "'mode', fill missing values with the mode of the column they are in.\n",
    "'most_frequent', fill missing values with the most frequent value in the column they are in (equivalent to 'mode' for numeric columns).\n",
    "'constant', provide a constant value to use to fill missing values.  A common choice for categorical data is 'missing'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleImputer in Python\n",
    "An overview of the steps:\n",
    "1. Import necessary libraries.\n",
    "2. Load and examine the data.\n",
    "3. Identify which columns have missing values and decide what imputation strategy to use to fill them.\n",
    "(We will take a slight detour here, but then backtrack to complete the below steps)\n",
    "4. Instantiate numeric and categorical column selectors.\n",
    "5. Instantiate SimpleImputer objects with the imputation strategies we want to use.\n",
    "6. Use ColumnTransformer to apply each different SimpleImputer object to the appropriate columns.\n",
    "7. Examine the data to ensure all missing data has been filled.\n",
    "\n",
    "To illustrate the use of the SimpleImputer we will  use the Medical Dataset for this example.  We will also use make_column_selector and make_column_transformer to apply different types of imputation strategies to different columns of our dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Area</th>\n",
       "      <th>Children</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ReAdmis</th>\n",
       "      <th>...</th>\n",
       "      <th>Hyperlipidemia</th>\n",
       "      <th>BackPain</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Allergic_rhinitis</th>\n",
       "      <th>Reflux_esophagitis</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Services</th>\n",
       "      <th>Initial_days</th>\n",
       "      <th>TotalCharge</th>\n",
       "      <th>Additional_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>34.34960</td>\n",
       "      <td>-86.72508</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53</td>\n",
       "      <td>86575.93</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood Work</td>\n",
       "      <td>10.585770</td>\n",
       "      <td>3726.702860</td>\n",
       "      <td>17939.403420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FL</td>\n",
       "      <td>30.84513</td>\n",
       "      <td>-85.22907</td>\n",
       "      <td>Urban</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51</td>\n",
       "      <td>46805.99</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Intravenous</td>\n",
       "      <td>15.129562</td>\n",
       "      <td>4193.190458</td>\n",
       "      <td>17612.998120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SD</td>\n",
       "      <td>43.54321</td>\n",
       "      <td>-96.63772</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53</td>\n",
       "      <td>14370.14</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Blood Work</td>\n",
       "      <td>4.772177</td>\n",
       "      <td>2434.234222</td>\n",
       "      <td>17505.192460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MN</td>\n",
       "      <td>43.89744</td>\n",
       "      <td>-93.51479</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>39741.49</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood Work</td>\n",
       "      <td>1.714879</td>\n",
       "      <td>2127.830423</td>\n",
       "      <td>12993.437350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VA</td>\n",
       "      <td>37.59894</td>\n",
       "      <td>-76.88958</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1209.56</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CT Scan</td>\n",
       "      <td>1.254807</td>\n",
       "      <td>2113.073274</td>\n",
       "      <td>3716.525786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State       Lat       Lng      Area  Children  Age    Income   Marital  \\\n",
       "0    AL  34.34960 -86.72508  Suburban       1.0   53  86575.93  Divorced   \n",
       "1    FL  30.84513 -85.22907     Urban       3.0   51  46805.99   Married   \n",
       "2    SD  43.54321 -96.63772  Suburban       3.0   53  14370.14   Widowed   \n",
       "3    MN  43.89744 -93.51479  Suburban       0.0   78  39741.49   Married   \n",
       "4    VA  37.59894 -76.88958     Rural       1.0   22   1209.56   Widowed   \n",
       "\n",
       "   Gender  ReAdmis  ...  Hyperlipidemia  BackPain  Anxiety  Allergic_rhinitis  \\\n",
       "0    Male        0  ...             0.0       1.0      1.0                1.0   \n",
       "1  Female        0  ...             0.0       0.0      0.0                0.0   \n",
       "2  Female        0  ...             0.0       0.0      0.0                0.0   \n",
       "3    Male        0  ...             0.0       0.0      0.0                0.0   \n",
       "4  Female        0  ...             1.0       0.0      0.0                1.0   \n",
       "\n",
       "   Reflux_esophagitis Asthma     Services  Initial_days  TotalCharge  \\\n",
       "0                   0      1   Blood Work     10.585770  3726.702860   \n",
       "1                   1      0  Intravenous     15.129562  4193.190458   \n",
       "2                   0      0   Blood Work      4.772177  2434.234222   \n",
       "3                   1      1   Blood Work      1.714879  2127.830423   \n",
       "4                   0      0      CT Scan      1.254807  2113.073274   \n",
       "\n",
       "   Additional_charges  \n",
       "0        17939.403420  \n",
       "1        17612.998120  \n",
       "2        17505.192460  \n",
       "3        12993.437350  \n",
       "4         3716.525786  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Libraries\n",
    " \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "\n",
    "# Read in the data\n",
    "path = r\"C:\\Users\\User\\github_projects\\Machine_Learning_with_Python\\datasets\\medical_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 32 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               995 non-null    object \n",
      " 1   Lat                 1000 non-null   float64\n",
      " 2   Lng                 1000 non-null   float64\n",
      " 3   Area                995 non-null    object \n",
      " 4   Children            993 non-null    float64\n",
      " 5   Age                 1000 non-null   int64  \n",
      " 6   Income              1000 non-null   float64\n",
      " 7   Marital             995 non-null    object \n",
      " 8   Gender              995 non-null    object \n",
      " 9   ReAdmis             1000 non-null   int64  \n",
      " 10  VitD_levels         1000 non-null   float64\n",
      " 11  Doc_visits          1000 non-null   int64  \n",
      " 12  Full_meals_eaten    1000 non-null   int64  \n",
      " 13  vitD_supp           1000 non-null   int64  \n",
      " 14  Soft_drink          1000 non-null   int64  \n",
      " 15  Initial_admin       995 non-null    object \n",
      " 16  HighBlood           1000 non-null   int64  \n",
      " 17  Stroke              1000 non-null   int64  \n",
      " 18  Complication_risk   995 non-null    object \n",
      " 19  Overweight          1000 non-null   int64  \n",
      " 20  Arthritis           994 non-null    float64\n",
      " 21  Diabetes            994 non-null    float64\n",
      " 22  Hyperlipidemia      998 non-null    float64\n",
      " 23  BackPain            992 non-null    float64\n",
      " 24  Anxiety             998 non-null    float64\n",
      " 25  Allergic_rhinitis   994 non-null    float64\n",
      " 26  Reflux_esophagitis  1000 non-null   int64  \n",
      " 27  Asthma              1000 non-null   int64  \n",
      " 28  Services            995 non-null    object \n",
      " 29  Initial_days        1000 non-null   float64\n",
      " 30  TotalCharge         1000 non-null   float64\n",
      " 31  Additional_charges  1000 non-null   float64\n",
      "dtypes: float64(14), int64(11), object(7)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Examine Missing Values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 missing values\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum().sum(), 'missing values')\n",
    "\n",
    "# There are 72 total missing values spread across 14 different columns.  \n",
    "# Some columns missing data are numeric and some are categorical (object). \n",
    "# We can use mean, median, mode, most_frequent, or constant imputation strategies for numeric data, but only constant or most_frequent strategies for categorical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: \n",
    "# If this were a real project we would investigate further to see if we should drop rows or columns missing data, or impute missing data. \n",
    "# The code below filters the dataset for just the rows that are missing at least 1 value and shows the shape.\n",
    "\n",
    "df[df.isna().any(axis=1)].shape\n",
    "\n",
    "\n",
    "# 70 rows out of 1000 are missing at least one value.  That is 0.7% of our data.  \n",
    "# In a real project we would probably just drop the rows with missing values with df.dropna().  \n",
    "# We could drop rows or columns before the validation split without leaking data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "# Imputing missing values can leak information from the testing data into the training data, so we impute values AFTER we split the data.\n",
    "\n",
    "# First, we define our target, \"Additional_charges\" as y and our features (the rest of the columns) as X.  Then we perform the train test split.  \n",
    "X = df.drop(columns=['Additional_charges'])\n",
    "y = df['Additional_charges']\n",
    "\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric columns are ['Lat', 'Lng', 'Children', 'Age', 'Income', 'ReAdmis', 'VitD_levels', 'Doc_visits', 'Full_meals_eaten', 'vitD_supp', 'Soft_drink', 'HighBlood', 'Stroke', 'Overweight', 'Arthritis', 'Diabetes', 'Hyperlipidemia', 'BackPain', 'Anxiety', 'Allergic_rhinitis', 'Reflux_esophagitis', 'Asthma', 'Initial_days', 'TotalCharge']\n",
      "categorical columns are ['State', 'Area', 'Marital', 'Gender', 'Initial_admin', 'Complication_risk', 'Services']\n"
     ]
    }
   ],
   "source": [
    "# Select Columns\n",
    "# We are going to separate our features into two types of columns based on the data type.  \n",
    "# One will be our numeric columns that will include both integers and floats.  \n",
    "# The other column with be the categorical columns that include our strings (objects).  \n",
    "\n",
    "#instantiate the selectors to for numeric and categorical data types\n",
    "num_selector = make_column_selector(dtype_include='number')\n",
    "cat_selector = make_column_selector(dtype_include='object')\n",
    "\n",
    "#select the numeric columns of each type\n",
    "num_columns = num_selector(X_train)\n",
    "cat_columns = cat_selector(X_train)\n",
    "\n",
    "#check our lists\n",
    "print('numeric columns are', num_columns)\n",
    "print('categorical columns are', cat_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Children</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hyperlipidemia</th>\n",
       "      <th>BackPain</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Allergic_rhinitis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Children  Arthritis  Diabetes  Hyperlipidemia  BackPain  Anxiety  \\\n",
       "0         1.0        1.0       1.0             0.0       1.0      1.0   \n",
       "1         3.0        0.0       0.0             0.0       0.0      0.0   \n",
       "2         3.0        0.0       1.0             0.0       0.0      0.0   \n",
       "3         0.0        1.0       0.0             0.0       0.0      0.0   \n",
       "4         1.0        0.0       NaN             1.0       0.0      0.0   \n",
       "..        ...        ...       ...             ...       ...      ...   \n",
       "995       3.0        0.0       1.0             1.0       0.0      0.0   \n",
       "996       2.0        1.0       0.0             NaN       1.0      1.0   \n",
       "997       0.0        1.0       0.0             1.0       1.0      0.0   \n",
       "998       0.0        1.0       0.0             0.0       0.0      0.0   \n",
       "999       1.0        0.0       0.0             0.0       1.0      0.0   \n",
       "\n",
       "     Allergic_rhinitis  \n",
       "0                  1.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  1.0  \n",
       "..                 ...  \n",
       "995                0.0  \n",
       "996                1.0  \n",
       "997                0.0  \n",
       "998                0.0  \n",
       "999                0.0  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method of Imputation\n",
    "# Before we decide which strategy to use for imputation, we need to understand our data.  \n",
    "# The code below will isolate the numeric columns that are missing data.  \n",
    "# We can do this to see what imputation strategy we should use.\n",
    "\n",
    "# isolate the numeric columns\n",
    "df_num = df[num_columns]\n",
    "\n",
    "# isolate the columns with missing data\n",
    "df_num.loc[:, df_num.isna().any()]\n",
    "\n",
    "\n",
    "# All of the numeric columns seem to have integer values (even though they are not integer datatypes).\n",
    "# If we used a 'mean' strategy those would be filled with decimal values (floats). \n",
    "# In order to fill them with integer values we need to use a 'median' strategy.  \n",
    "# In fact, all of the columns above except 'children' are actually boolean values.  0.0 represents 'no' and 1.0 represents 'yes'.  \n",
    "# We especially don't want decimal values for number of children or yes/no data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                  True\n",
       "Lat                   False\n",
       "Lng                   False\n",
       "Area                   True\n",
       "Children               True\n",
       "Age                   False\n",
       "Income                False\n",
       "Marital                True\n",
       "Gender                 True\n",
       "ReAdmis               False\n",
       "VitD_levels           False\n",
       "Doc_visits            False\n",
       "Full_meals_eaten      False\n",
       "vitD_supp             False\n",
       "Soft_drink            False\n",
       "Initial_admin          True\n",
       "HighBlood             False\n",
       "Stroke                False\n",
       "Complication_risk      True\n",
       "Overweight            False\n",
       "Arthritis              True\n",
       "Diabetes               True\n",
       "Hyperlipidemia         True\n",
       "BackPain               True\n",
       "Anxiety                True\n",
       "Allergic_rhinitis      True\n",
       "Reflux_esophagitis    False\n",
       "Asthma                False\n",
       "Services               True\n",
       "Initial_days          False\n",
       "TotalCharge           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Imputer without ColumnTransformer\n",
    "# First, let's check which columns are missing data.\n",
    "X_train.isna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code shows how to apply the Simple Imputer to the columns that were previously selected as and defined as num_columns. \n",
    "# Note that the step with .fit is only applied to the training set!\n",
    "\n",
    "#Instantiate the imputer object from the SimpleImputer class with strategy 'median'\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "#Fit the imputer object on the numeric training data with .fit() \n",
    "#calculates the medians of the columns in the training set\n",
    "median_imputer.fit(X_train[num_columns])\n",
    "\n",
    "#Use the median from the training data to fill the missing values in \n",
    "#the numeric columns of both the training and testing sets with .transform()\n",
    "X_train.loc[:, num_columns] = median_imputer.transform(X_train[num_columns])\n",
    "X_test.loc[:, num_columns] = median_imputer.transform(X_test[num_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                  True\n",
       "Lat                   False\n",
       "Lng                   False\n",
       "Area                   True\n",
       "Children              False\n",
       "Age                   False\n",
       "Income                False\n",
       "Marital                True\n",
       "Gender                 True\n",
       "ReAdmis               False\n",
       "VitD_levels           False\n",
       "Doc_visits            False\n",
       "Full_meals_eaten      False\n",
       "vitD_supp             False\n",
       "Soft_drink            False\n",
       "Initial_admin          True\n",
       "HighBlood             False\n",
       "Stroke                False\n",
       "Complication_risk      True\n",
       "Overweight            False\n",
       "Arthritis             False\n",
       "Diabetes              False\n",
       "Hyperlipidemia        False\n",
       "BackPain              False\n",
       "Anxiety               False\n",
       "Allergic_rhinitis     False\n",
       "Reflux_esophagitis    False\n",
       "Asthma                False\n",
       "Services               True\n",
       "Initial_days          False\n",
       "TotalCharge           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Did SimpleImputer fill the missing values in X_train?\n",
    "X_train.isna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                  True\n",
       "Lat                   False\n",
       "Lng                   False\n",
       "Area                   True\n",
       "Children               True\n",
       "Age                   False\n",
       "Income                False\n",
       "Marital                True\n",
       "Gender                 True\n",
       "ReAdmis               False\n",
       "VitD_levels           False\n",
       "Doc_visits            False\n",
       "Full_meals_eaten      False\n",
       "vitD_supp             False\n",
       "Soft_drink            False\n",
       "Initial_admin          True\n",
       "HighBlood             False\n",
       "Stroke                False\n",
       "Complication_risk      True\n",
       "Overweight            False\n",
       "Arthritis              True\n",
       "Diabetes               True\n",
       "Hyperlipidemia         True\n",
       "BackPain               True\n",
       "Anxiety                True\n",
       "Allergic_rhinitis      True\n",
       "Reflux_esophagitis    False\n",
       "Asthma                False\n",
       "Services               True\n",
       "Initial_days          False\n",
       "TotalCharge           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SimpleImputer with ColumnTransformer\n",
    "# Let's recreate our original X_train with all of the missing values and see how ColumnTransformer, combined with SimpleImputer, \n",
    "# can impute both the numeric columns with medians and the categorical columns with the most frequent value.\n",
    "\n",
    "# Create a New X_train With Missing Values\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train.isna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate ColumnSelectors\n",
    "#instantiate the selectors to for numeric and categorical data types\n",
    "num_selector = make_column_selector(dtype_include='number')\n",
    "cat_selector = make_column_selector(dtype_include='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Imputers\n",
    "# We will fill missing data in numeric columns with the median of each column and missing data in categorical columns with the most frequent value.  \n",
    "# These are not the only options, but it's what we will do today.\n",
    "#instantiate SimpleImputers with most_frequent and median strategies\n",
    "freq_imputer = SimpleImputer(strategy='most_frequent')\n",
    "median_imputer = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;simpleimputer-1&#x27;,\n",
       "                                 SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000017EB5CF2790&gt;),\n",
       "                                (&#x27;simpleimputer-2&#x27;,\n",
       "                                 SimpleImputer(strategy=&#x27;most_frequent&#x27;),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000017EB5CF02D0&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;simpleimputer-1&#x27;,\n",
       "                                 SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000017EB5CF2790&gt;),\n",
       "                                (&#x27;simpleimputer-2&#x27;,\n",
       "                                 SimpleImputer(strategy=&#x27;most_frequent&#x27;),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000017EB5CF02D0&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">simpleimputer-1</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000017EB5CF2790&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">simpleimputer-2</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000017EB5CF02D0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('simpleimputer-1',\n",
       "                                 SimpleImputer(strategy='median'),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000017EB5CF2790>),\n",
       "                                ('simpleimputer-2',\n",
       "                                 SimpleImputer(strategy='most_frequent'),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000017EB5CF02D0>)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the ColumnTransformer\n",
    "# As you recall from other lessons, make_column_transformer() takes tuples of the form (transformer, columns).  \n",
    "# ColumnSelectors can be used instead of lists of columns.  Both are acceptable.  \n",
    "# We can set remainder='passthrough' if we are not applying transformers to all columns.  \n",
    "# We might do this if we imputed some columns by hand already. \n",
    "# The default for ColumnTransformer is to drop any columns that are not specified in a tuple, \n",
    "# while remainder = 'passthrough' retains the original values for any columns not specified in a tuple without any transformation.\n",
    "\n",
    "# create tuples of (imputer, selector) for each datatype\n",
    "num_tuple = (median_imputer, num_selector)\n",
    "cat_tuple = (freq_imputer, cat_selector)\n",
    "\n",
    "# instantiate ColumnTransformer\n",
    "col_transformer = make_column_transformer(num_tuple, cat_tuple, remainder='passthrough')\n",
    "col_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                 False\n",
       "Lat                   False\n",
       "Lng                   False\n",
       "Area                  False\n",
       "Children              False\n",
       "Age                   False\n",
       "Income                False\n",
       "Marital               False\n",
       "Gender                False\n",
       "ReAdmis               False\n",
       "VitD_levels           False\n",
       "Doc_visits            False\n",
       "Full_meals_eaten      False\n",
       "vitD_supp             False\n",
       "Soft_drink            False\n",
       "Initial_admin         False\n",
       "HighBlood             False\n",
       "Stroke                False\n",
       "Complication_risk     False\n",
       "Overweight            False\n",
       "Arthritis             False\n",
       "Diabetes              False\n",
       "Hyperlipidemia        False\n",
       "BackPain              False\n",
       "Anxiety               False\n",
       "Allergic_rhinitis     False\n",
       "Reflux_esophagitis    False\n",
       "Asthma                False\n",
       "Services              False\n",
       "Initial_days          False\n",
       "TotalCharge           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute Missing Values With ColumnTransformer\n",
    "# fit ColumnTransformer on the training data\n",
    "col_transformer.fit(X_train)\n",
    "\n",
    "# transform both the training and testing data (this will output a NumPy array)\n",
    "X_train_imputed = col_transformer.transform(X_train)\n",
    "X_test_imputed = col_transformer.transform(X_test)\n",
    "\n",
    "# change the result back to a dataframe\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "X_train_imputed.isna().any()\n",
    "\n",
    "\n",
    "# You can see that our dataframe is now free of missing values.  \n",
    "# Using ColumnTransformer reduces the complexity of our code, reduces the chances for errors, and you will see later that we can use it with other tools to streamline the modeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "# SimpleImputer can impute missing values in many columns at once.  \n",
    "# It can also help avoid data leakage.  \n",
    "# If we use SimpleImputer and ColumnTransformer together, we can easily apply different imputation strategies to different columns simultaneously.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
