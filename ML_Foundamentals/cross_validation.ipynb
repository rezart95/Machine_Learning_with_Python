{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Cross-Validation?\n",
    "# Cross-validation creates and trains multiple identical models using different subsets of the data. For each model, the data is split into\n",
    "# different training sets and testing sets in such a way that each sample is used in a testing set during one split. Each new train/test split\n",
    "# of the data is called a fold.\n",
    "# In the image above each row represents a different fold. The blue rectangles are the testing set for each fold. K number of models are\n",
    "# trained on the training data for each of the k folds and evaluated on the testing data. The scores for each fold are recorded.\n",
    "# Since the image above is k=5, or 5 folds, a different 20% of the data is used as a test set for each fold so that over 5 iterations every\n",
    "# piece of the data is used for both training and testing.\n",
    "# Hold-out set. Notice on the bottom left the ‘Test data’? We only use our training data for the cross-validation and hold out our test data\n",
    "# for evaluating the very final model we choose, after model selection and hyperparameter tuning.\n",
    "\n",
    "\n",
    "\n",
    "# Why Use Cross-Validation?\n",
    "# There are two primary reasons to use cross-validation.\n",
    "# Cross-Validation Compares Model Performance on Multiple Test Sets\n",
    "# Model scores often vary if different subsets of the data are used for evaluation. Sometimes testing sets are not representative of the\n",
    "# entire dataset, or certain outliers in the data are harder to predict. Cross-validation returns scores for all parts of the data. This\n",
    "# increases confidence in how the model may perform on new data since new data will not be identical to any one test set.\n",
    "# Cross-Validation Prevents Overfitting to a Single Test Set.\n",
    "# You have learned about overfitting to a training set, but it’s also possible to overfit to a test set. This can occur when models and\n",
    "# hyperparameters are chosen because they work well on one particular test set, but may not work well for other data. While no\n",
    "# individual model has been fitted to the test set, you as a data scientist have fit your choice of model and hyperparameters to perform\n",
    "# well on one particular test set. Will that model with those parameters work well with new data as well?\n",
    "# When we use cross-validation we only use the training data for the folds. This allows us to test each model using only data from the\n",
    "# training set while still using a validation split. If we use cross-validation to choose a model and hyperparameters, then just use the\n",
    "# original test set for evaluation of the final model, we can increase our confidence in the performance of the model on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation in Python\n",
    "# Scikit-Learn has several tools for cross-validation. One of them is:\n",
    "\n",
    "# sklearn.model_selection.cross_val_score\n",
    "\n",
    "# The function above takes a model (or pipeline), an X set of features, a y set of labels, and optionally a scoring function. You can also\n",
    "# define the number of folds you want to use. See the documentation on cross_val_score to learn more.\n",
    "# cross_val_score returns an array of scores, one for each fold. A common way to compare the scores across many models is to average\n",
    "# them.\n",
    "\n",
    "# Preventing Data Leakage During Cross-Validation\n",
    "# Since each portion of the training set will be used as a testing set during cross-validation, we will need to apply any preprocessing\n",
    "# separately to prevent overfitting in each fold. We can do this by using a pipeline in place of our model in the code."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
