{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import random forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "# We will use the California housing data set that we used when learning about decision trees.\n",
    "df = pd.read_csv('C:\\\\Users\\\\User\\\\github_projects\\\\Machine_Learning_with_Python\\\\datasets\\\\cali_housing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into a features matrix and target vector and train-test-split\n",
    "# Arrange Data into Features Matrix and Target Vector\n",
    "y = df['MedHouseVal']\n",
    "X = df.drop(columns = 'MedHouseVal')\n",
    "\n",
    "# Split the data for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Import the model you want to use\n",
    "# In sklearn, all machine learning models are implemented as Python classes\n",
    "# This was already imported earlier so commenting it out\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Step 2: Make an instance of the Model\n",
    "# This is a place where we can tune the hyperparameters of a model. At the moment, let's use the defaults parameters.  \n",
    "# You can see that this will be Max_depth = None and n_estimators = 100.  \n",
    "# These are just a few of the important parameters to explore!\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Looking at some hyperparameters that seem tunable\n",
    "rf.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9726171894816914\n",
      "0.8078595561901133\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Training the model on the data, storing the information learned from the data\n",
    "# Model is learning the relationship between X and y. Note that this may take some time to run!\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predict the values for y (remember that this step just allows you to see the actual predictions, but is not necessary for evaluating or tuning your model)\n",
    "rf.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate your model performance\n",
    "rf_train_score = rf.score(X_train, y_train)\n",
    "rf_test_score = rf.score(X_test, y_test)\n",
    "print(rf_train_score)\n",
    "print(rf_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8422908368094096\n",
      "0.7659811625575986\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Tune your model\n",
    "# Tuning the max_depth\n",
    "# As we did previously, we can tune the max_depth we allow for each tree in our random forest. \n",
    "# Let's set the max_depth to 9 and evaluate our results.\n",
    "\n",
    "rf_9 = RandomForestRegressor(max_depth = 9, random_state = 42)\n",
    "rf_9.fit(X_train, y_train)\n",
    "rf_9_train_score = rf_9.score(X_train, y_train)\n",
    "rf_9_test_score = rf_9.score(X_test, y_test)\n",
    "print(rf_9_train_score)\n",
    "print(rf_9_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34,\n",
       " 32,\n",
       " 35,\n",
       " 32,\n",
       " 32,\n",
       " 31,\n",
       " 30,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 32,\n",
       " 29,\n",
       " 32,\n",
       " 34,\n",
       " 32,\n",
       " 32,\n",
       " 30,\n",
       " 31,\n",
       " 31,\n",
       " 32,\n",
       " 34,\n",
       " 30,\n",
       " 31,\n",
       " 33,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 35,\n",
       " 30,\n",
       " 37,\n",
       " 31,\n",
       " 31,\n",
       " 34,\n",
       " 32,\n",
       " 29,\n",
       " 33,\n",
       " 33,\n",
       " 31,\n",
       " 32,\n",
       " 29,\n",
       " 34,\n",
       " 36,\n",
       " 34,\n",
       " 31,\n",
       " 32,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 32,\n",
       " 35,\n",
       " 36,\n",
       " 32,\n",
       " 37,\n",
       " 32,\n",
       " 32,\n",
       " 35,\n",
       " 31,\n",
       " 33,\n",
       " 34,\n",
       " 32,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 31,\n",
       " 34,\n",
       " 30,\n",
       " 30,\n",
       " 32,\n",
       " 31,\n",
       " 33,\n",
       " 32,\n",
       " 33,\n",
       " 33,\n",
       " 30,\n",
       " 34,\n",
       " 32,\n",
       " 42,\n",
       " 36,\n",
       " 31,\n",
       " 33,\n",
       " 30,\n",
       " 32,\n",
       " 31,\n",
       " 37,\n",
       " 37,\n",
       " 34,\n",
       " 33,\n",
       " 31,\n",
       " 33,\n",
       " 33,\n",
       " 30,\n",
       " 33,\n",
       " 32,\n",
       " 34,\n",
       " 31,\n",
       " 31,\n",
       " 33,\n",
       " 34]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that while our results with a max_depth of 9 were optimal for the single tree, this is NOT the case for the random forest! (Our test score decreased)\n",
    "# To see what the depth of each tree in your random forest was when the max_depth was unlimited, you can use the following code:\n",
    "\n",
    "[estimator.get_depth() for estimator in rf.estimators_]\n",
    "\n",
    "# To save space, the output is not shown here,  however notice that the depth of each tree varies.  \n",
    "# You can try different values for max_depth or other parameters to see if you can make improvements on the default model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736513985866985\n",
      "0.8094548562033245\n"
     ]
    }
   ],
   "source": [
    "# Tuning n_estimators (# of decision trees)\n",
    "# Another tuning parameter is n_estimators, which represents the number of trees that should be grown. \n",
    "# The code below can take some time to run. The reason is that when you train an ensemble you are training more than one model (in this case tree).  \n",
    "# Let's see if we can improve our score by doubling the amount of trees from 100 to 200.  \n",
    "\n",
    "# Try 200 trees\n",
    "rf_200 = RandomForestRegressor(n_estimators = 200, random_state = 42)\n",
    "\n",
    "# Fit the model\n",
    "rf_200.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the scores\n",
    "rf_200_train_score = rf_200.score(X_train, y_train)\n",
    "rf_200_test_score = rf_200.score(X_test, y_test)\n",
    "print(rf_200_train_score)\n",
    "print(rf_200_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that, in this case,  we hardly had any noticeable improvement with 200 trees compared to the default 100 trees.  \n",
    "# This will depend on your data.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
