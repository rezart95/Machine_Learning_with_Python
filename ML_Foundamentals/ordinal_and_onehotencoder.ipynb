{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is One-hot Encoding?\n",
    "# First, one-hot encoding does NOT capture the meaning of the words. \n",
    "# The computer does not know what blue looks like, but it can still find relationships between the color and other variables in the context\n",
    "# of a dataset. In order to represent non-ordered, or 'nominal' features, we do the following:\n",
    "# 1. Create a new column for every category present in the feature.\n",
    "# 2. Set the value of each of the new columns to 1 if that row corresponds to the original category\n",
    "# 3. Set the value of each of the new columns to 0 if they do not.\n",
    "# 4. Remove the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Area</th>\n",
       "      <th>Children</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>Hyperlipidemia</th>\n",
       "      <th>BackPain</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Allergic_rhinitis</th>\n",
       "      <th>Reflux_esophagitis</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Services</th>\n",
       "      <th>Initial_days</th>\n",
       "      <th>TotalCharge</th>\n",
       "      <th>Additional_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>34.34960</td>\n",
       "      <td>-86.72508</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53</td>\n",
       "      <td>86575.93</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood Work</td>\n",
       "      <td>10.585770</td>\n",
       "      <td>3726.702860</td>\n",
       "      <td>17939.403420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FL</td>\n",
       "      <td>30.84513</td>\n",
       "      <td>-85.22907</td>\n",
       "      <td>Urban</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51</td>\n",
       "      <td>46805.99</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Intravenous</td>\n",
       "      <td>15.129562</td>\n",
       "      <td>4193.190458</td>\n",
       "      <td>17612.998120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SD</td>\n",
       "      <td>43.54321</td>\n",
       "      <td>-96.63772</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53</td>\n",
       "      <td>14370.14</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Blood Work</td>\n",
       "      <td>4.772177</td>\n",
       "      <td>2434.234222</td>\n",
       "      <td>17505.192460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MN</td>\n",
       "      <td>43.89744</td>\n",
       "      <td>-93.51479</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>39741.49</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood Work</td>\n",
       "      <td>1.714879</td>\n",
       "      <td>2127.830423</td>\n",
       "      <td>12993.437350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>VA</td>\n",
       "      <td>37.59894</td>\n",
       "      <td>-76.88958</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1209.56</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CT Scan</td>\n",
       "      <td>1.254807</td>\n",
       "      <td>2113.073274</td>\n",
       "      <td>3716.525786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 State       Lat       Lng      Area  Children  Age    Income  \\\n",
       "0           1    AL  34.34960 -86.72508  Suburban       1.0   53  86575.93   \n",
       "1           2    FL  30.84513 -85.22907     Urban       3.0   51  46805.99   \n",
       "2           3    SD  43.54321 -96.63772  Suburban       3.0   53  14370.14   \n",
       "3           4    MN  43.89744 -93.51479  Suburban       0.0   78  39741.49   \n",
       "4           5    VA  37.59894 -76.88958     Rural       1.0   22   1209.56   \n",
       "\n",
       "    Marital  Gender  ...  Hyperlipidemia  BackPain  Anxiety  \\\n",
       "0  Divorced    Male  ...             0.0       1.0      1.0   \n",
       "1   Married  Female  ...             0.0       0.0      0.0   \n",
       "2   Widowed  Female  ...             0.0       0.0      0.0   \n",
       "3   Married    Male  ...             0.0       0.0      0.0   \n",
       "4   Widowed  Female  ...             1.0       0.0      0.0   \n",
       "\n",
       "   Allergic_rhinitis  Reflux_esophagitis  Asthma     Services  Initial_days  \\\n",
       "0                1.0                   0       1   Blood Work     10.585770   \n",
       "1                0.0                   1       0  Intravenous     15.129562   \n",
       "2                0.0                   0       0   Blood Work      4.772177   \n",
       "3                0.0                   1       1   Blood Work      1.714879   \n",
       "4                1.0                   0       0      CT Scan      1.254807   \n",
       "\n",
       "   TotalCharge Additional_charges  \n",
       "0  3726.702860       17939.403420  \n",
       "1  4193.190458       17612.998120  \n",
       "2  2434.234222       17505.192460  \n",
       "3  2127.830423       12993.437350  \n",
       "4  2113.073274        3716.525786  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "path = 'C:/Users/User/Desktop/Raw_Medical_Data_for_day1.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "path = 'C:/Users/User/Desktop/Raw_Medical_Data_for_day1.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# There are several 'object' columns that will need to be encoded.\n",
    "df.info()\n",
    "\n",
    "# The column 'Complication_Risk' is actually ordered and we can use ordinal encoding for that one. The df.replace() method works great for this.\n",
    "df['Complication_risk'].value_counts()\n",
    "\n",
    "df['Complication_risk'].replace({'Low':0, 'Med':1, 'Medium':1, 'High':2}, inplace=True)\n",
    "df['Complication_risk'].value_counts()\n",
    "\n",
    "# The ordinal encoding we performed above did not depend on information from the test data, so does not cause data leakage. We can do this before we split the data.\n",
    "\n",
    "# For this task, the goal is to predict \"Additional charges\" based on the other features in the dataset.\n",
    "# We will assign \"Additional_charges\" as our target, y.\n",
    "# We will assign the rest of the columns as our features (X). We will also drop the \"Unnamed: 0\" column because it is not a relevant feature.\n",
    "\n",
    "X = df.drop(columns = ['Unnamed: 0', 'Additional_charges'])\n",
    "y = df['Additional_charges']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Selector\n",
    "# We only want to one-hot encode the categorical features, NOT the numeric features, so we need a way to split off the categorical features from the numeric ones. We could do this manually, but make_column_selector will allow us to this more efficiently.\n",
    "# When we instantiate the make_column_selector, we use the 'dtype_include= ____ argument to tell it what kinds of columns we want it to select. By passing the argument 'dtype_include='object', it will select\n",
    "# columns with the 'object' datatype. If, instead, we were to set 'dtype_include='number'', it would select both integer and float datatypes, since those are both numbers.\n",
    "# In this case we will tell make_column_selector to only select columns with the type 'object'.\n",
    "\n",
    "#make categorical selector\n",
    "cat_selector = make_column_selector(dtype_include='object')\n",
    "\n",
    "# When we apply the cat_selector to a dataframe, it will return a list of the column names of the columns that match the pattern we gave it.\n",
    "cat_selector(X_train)\n",
    "\n",
    "# We can now use that list to subset the original dataset.\n",
    "# The code below creates two new dataframes '(train_cat_data' and 'test_cat_data') that contain only the object features selected with the cat_selector.\n",
    "\n",
    "# create a subset of data for only categorical columns\n",
    "train_cat_data = X_train[cat_selector(X_train)]\n",
    "test_cat_data = X_test[cat_selector(X_test)]\n",
    "train_cat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHotEncoder\n",
    "# Scikit-Learn's OneHotEncoder class will do all of the one-hot encoding work for us, but we want to make some changes from default settings when we instantiate the OneHotEncoder.\n",
    "# sparse = False\n",
    "# Be default, it will return what is called a 'sparse matrix'. This is a form of data compression used when arrays are mostly filled with 0s. Instead of keeping track of so many 0s, the compressed version just\n",
    "# has information about where the data is NOT 0. This is great for saving memory! But not great if we want to use the data in a new dataframe. We can get OneHotEncoder to return a normal array that is\n",
    "# compatible with pandas, called a ‘Dense’ array by specifying ‘sparse=False’ inside our OneHotEncoder.\n",
    "# handle_unknown ='ignore'\n",
    "# OneHotEncoder is a transformer like StandardScaler. When we use it we will:\n",
    "# 1. Fit the OneHotEncoder ONLY on the categorical training data\n",
    "# 2. Transform the categorical training data to a one-hot encoded form.\n",
    "# 3. Transform the categorical testing data to a one-hot encoded form.\n",
    "# Be default, OneHotEncoder will throw an error if we try to transform data that has categories that were not present in the data it was fitted on and does not have columns for. We can pass the argument\n",
    "# 'handle_unknown='ignore'' to tell it to ignore any categories that were not present during the fit step (values it encounters in the test set that were not present in the train set). In this case, all columns\n",
    "# corresponding to that feature will have the value 0.\n",
    "\n",
    "#instantiate one hot encoder\n",
    "ohe_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "#fit the OneHotEncoder on the training data\n",
    "ohe_encoder.fit(train_cat_data)\n",
    "\n",
    "#transform both the training and the testing data\n",
    "train_ohe = ohe_encoder.transform(train_cat_data)\n",
    "test_ohe = ohe_encoder.transform(test_cat_data)\n",
    "train_ohe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_AK</th>\n",
       "      <th>State_AL</th>\n",
       "      <th>State_AR</th>\n",
       "      <th>State_AZ</th>\n",
       "      <th>State_CA</th>\n",
       "      <th>State_CO</th>\n",
       "      <th>State_CT</th>\n",
       "      <th>State_DC</th>\n",
       "      <th>State_FL</th>\n",
       "      <th>State_GA</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender_f</th>\n",
       "      <th>Gender_m</th>\n",
       "      <th>Gender_male</th>\n",
       "      <th>Initial_admin_Elective Admission</th>\n",
       "      <th>Initial_admin_Emergency Admission</th>\n",
       "      <th>Initial_admin_Observation Admission</th>\n",
       "      <th>Services_Blood Work</th>\n",
       "      <th>Services_CT Scan</th>\n",
       "      <th>Services_Intravenous</th>\n",
       "      <th>Services_MRI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     State_AK  State_AL  State_AR  State_AZ  State_CA  State_CO  State_CT  \\\n",
       "0         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1         0.0       1.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "745       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "746       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "747       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "748       0.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "749       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "     State_DC  State_FL  State_GA  ...  Gender_f  Gender_m  Gender_male  \\\n",
       "0         0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "1         0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "2         0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "3         0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "4         0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "..        ...       ...       ...  ...       ...       ...          ...   \n",
       "745       0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "746       0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "747       0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "748       0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "749       0.0       0.0       0.0  ...       0.0       0.0          0.0   \n",
       "\n",
       "     Initial_admin_Elective Admission  Initial_admin_Emergency Admission  \\\n",
       "0                                 0.0                                1.0   \n",
       "1                                 0.0                                1.0   \n",
       "2                                 0.0                                0.0   \n",
       "3                                 0.0                                0.0   \n",
       "4                                 1.0                                0.0   \n",
       "..                                ...                                ...   \n",
       "745                               0.0                                0.0   \n",
       "746                               0.0                                0.0   \n",
       "747                               1.0                                0.0   \n",
       "748                               0.0                                0.0   \n",
       "749                               0.0                                0.0   \n",
       "\n",
       "     Initial_admin_Observation Admission  Services_Blood Work  \\\n",
       "0                                    0.0                  0.0   \n",
       "1                                    0.0                  1.0   \n",
       "2                                    1.0                  0.0   \n",
       "3                                    1.0                  1.0   \n",
       "4                                    0.0                  1.0   \n",
       "..                                   ...                  ...   \n",
       "745                                  1.0                  0.0   \n",
       "746                                  1.0                  1.0   \n",
       "747                                  0.0                  1.0   \n",
       "748                                  1.0                  1.0   \n",
       "749                                  1.0                  1.0   \n",
       "\n",
       "     Services_CT Scan  Services_Intravenous  Services_MRI  \n",
       "0                 0.0                   1.0           0.0  \n",
       "1                 0.0                   0.0           0.0  \n",
       "2                 0.0                   1.0           0.0  \n",
       "3                 0.0                   0.0           0.0  \n",
       "4                 0.0                   0.0           0.0  \n",
       "..                ...                   ...           ...  \n",
       "745               0.0                   1.0           0.0  \n",
       "746               0.0                   0.0           0.0  \n",
       "747               0.0                   0.0           0.0  \n",
       "748               0.0                   0.0           0.0  \n",
       "749               0.0                   0.0           0.0  \n",
       "\n",
       "[750 rows x 72 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that the output is a Numpy array instead of a dataframe. This is fine for modeling, but makes it difficult to inspect the result, and we can't use Pandas to manipulate it. Converting the output to a\n",
    "# dataframe is not necessary for modeling, but we will do it so now so we can see the result more clearly and so we can recombine the new one hot encoded columns with our numeric columns.\n",
    "# We can use the method 'get_feature_names_out()' to get a list of the new features, but we need to pass it the original list of columns (from before the data was encoded).\n",
    "\n",
    "#set prefixes to original column names\n",
    "ohe_column_names = ohe_encoder.get_feature_names_out()\n",
    "train_ohe = pd.DataFrame(train_ohe, columns=ohe_column_names)\n",
    "test_ohe = pd.DataFrame(test_ohe, columns=ohe_column_names)\n",
    "train_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Children</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>ReAdmis</th>\n",
       "      <th>VitD_levels</th>\n",
       "      <th>Doc_visits</th>\n",
       "      <th>Full_meals_eaten</th>\n",
       "      <th>vitD_supp</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender_f</th>\n",
       "      <th>Gender_m</th>\n",
       "      <th>Gender_male</th>\n",
       "      <th>Initial_admin_Elective Admission</th>\n",
       "      <th>Initial_admin_Emergency Admission</th>\n",
       "      <th>Initial_admin_Observation Admission</th>\n",
       "      <th>Services_Blood Work</th>\n",
       "      <th>Services_CT Scan</th>\n",
       "      <th>Services_Intravenous</th>\n",
       "      <th>Services_MRI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.16307</td>\n",
       "      <td>-86.66510</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>8459.99</td>\n",
       "      <td>0</td>\n",
       "      <td>19.034162</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.96594</td>\n",
       "      <td>-87.12179</td>\n",
       "      <td>5.0</td>\n",
       "      <td>78</td>\n",
       "      <td>22669.31</td>\n",
       "      <td>0</td>\n",
       "      <td>15.903388</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.24648</td>\n",
       "      <td>-83.51232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>25536.25</td>\n",
       "      <td>0</td>\n",
       "      <td>18.225040</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.42189</td>\n",
       "      <td>-97.91165</td>\n",
       "      <td>7.0</td>\n",
       "      <td>82</td>\n",
       "      <td>94863.57</td>\n",
       "      <td>0</td>\n",
       "      <td>15.809932</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.33661</td>\n",
       "      <td>-83.28292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>30898.36</td>\n",
       "      <td>0</td>\n",
       "      <td>20.640410</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>42.05701</td>\n",
       "      <td>-77.43901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>4788.93</td>\n",
       "      <td>0</td>\n",
       "      <td>19.029312</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>40.47773</td>\n",
       "      <td>-86.38658</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27</td>\n",
       "      <td>29461.62</td>\n",
       "      <td>0</td>\n",
       "      <td>15.293840</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>40.56510</td>\n",
       "      <td>-81.07429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>79094.04</td>\n",
       "      <td>0</td>\n",
       "      <td>19.459084</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>33.97472</td>\n",
       "      <td>-118.35549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>25697.12</td>\n",
       "      <td>0</td>\n",
       "      <td>15.871725</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>40.75848</td>\n",
       "      <td>-73.69730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "      <td>79759.72</td>\n",
       "      <td>0</td>\n",
       "      <td>17.898182</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lat        Lng  Children  Age    Income  ReAdmis  VitD_levels  \\\n",
       "0    36.16307  -86.66510       2.0   60   8459.99        0    19.034162   \n",
       "1    34.96594  -87.12179       5.0   78  22669.31        0    15.903388   \n",
       "2    36.24648  -83.51232       1.0   60  25536.25        0    18.225040   \n",
       "3    45.42189  -97.91165       7.0   82  94863.57        0    15.809932   \n",
       "4    42.33661  -83.28292       0.0   37  30898.36        0    20.640410   \n",
       "..        ...        ...       ...  ...       ...      ...          ...   \n",
       "745  42.05701  -77.43901       1.0   32   4788.93        0    19.029312   \n",
       "746  40.47773  -86.38658       4.0   27  29461.62        0    15.293840   \n",
       "747  40.56510  -81.07429       0.0   57  79094.04        0    19.459084   \n",
       "748  33.97472 -118.35549       0.0   56  25697.12        0    15.871725   \n",
       "749  40.75848  -73.69730       0.0   89  79759.72        0    17.898182   \n",
       "\n",
       "     Doc_visits  Full_meals_eaten  vitD_supp  ...  Gender_f  Gender_m  \\\n",
       "0             5                 1          0  ...       0.0       0.0   \n",
       "1             7                 1          0  ...       0.0       0.0   \n",
       "2             4                 1          0  ...       0.0       0.0   \n",
       "3             5                 0          2  ...       0.0       0.0   \n",
       "4             5                 1          0  ...       0.0       0.0   \n",
       "..          ...               ...        ...  ...       ...       ...   \n",
       "745           6                 1          0  ...       0.0       0.0   \n",
       "746           5                 0          0  ...       0.0       0.0   \n",
       "747           5                 0          0  ...       0.0       0.0   \n",
       "748           5                 1          0  ...       0.0       0.0   \n",
       "749           3                 1          1  ...       0.0       0.0   \n",
       "\n",
       "     Gender_male  Initial_admin_Elective Admission  \\\n",
       "0            0.0                               0.0   \n",
       "1            0.0                               0.0   \n",
       "2            0.0                               0.0   \n",
       "3            0.0                               0.0   \n",
       "4            0.0                               1.0   \n",
       "..           ...                               ...   \n",
       "745          0.0                               0.0   \n",
       "746          0.0                               0.0   \n",
       "747          0.0                               1.0   \n",
       "748          0.0                               0.0   \n",
       "749          0.0                               0.0   \n",
       "\n",
       "     Initial_admin_Emergency Admission  Initial_admin_Observation Admission  \\\n",
       "0                                  1.0                                  0.0   \n",
       "1                                  1.0                                  0.0   \n",
       "2                                  0.0                                  1.0   \n",
       "3                                  0.0                                  1.0   \n",
       "4                                  0.0                                  0.0   \n",
       "..                                 ...                                  ...   \n",
       "745                                0.0                                  1.0   \n",
       "746                                0.0                                  1.0   \n",
       "747                                0.0                                  0.0   \n",
       "748                                0.0                                  1.0   \n",
       "749                                0.0                                  1.0   \n",
       "\n",
       "     Services_Blood Work  Services_CT Scan  Services_Intravenous  Services_MRI  \n",
       "0                    0.0               0.0                   1.0           0.0  \n",
       "1                    1.0               0.0                   0.0           0.0  \n",
       "2                    0.0               0.0                   1.0           0.0  \n",
       "3                    1.0               0.0                   0.0           0.0  \n",
       "4                    1.0               0.0                   0.0           0.0  \n",
       "..                   ...               ...                   ...           ...  \n",
       "745                  0.0               0.0                   1.0           0.0  \n",
       "746                  1.0               0.0                   0.0           0.0  \n",
       "747                  1.0               0.0                   0.0           0.0  \n",
       "748                  1.0               0.0                   0.0           0.0  \n",
       "749                  1.0               0.0                   0.0           0.0  \n",
       "\n",
       "[750 rows x 97 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a numeric selector\n",
    "num_selector = make_column_selector(dtype_include='number')\n",
    "# isolate the numeric columns\n",
    "train_nums = X_train[num_selector(X_train)].reset_index(drop=True)\n",
    "test_nums = X_test[num_selector(X_test)].reset_index(drop=True)\n",
    "# re-combine the train and test sets on axis 1 (columns)\n",
    "X_train_processed = pd.concat([train_nums, train_ohe], axis=1)\n",
    "X_test_processed = pd.concat([test_nums, test_ohe], axis=1)\n",
    "X_train_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns in our dataframe are now numeric with no data lost. \n",
    "# This dataframe can be used in a model, however, we may want to scale the numeric columns as well if we are using certain kinds of models. \n",
    "\n",
    "# Why can't we one-hot encode data before we split?\n",
    "# The short answer is because it causes data leakage. Let's examine how.\n",
    "\n",
    "# Sometimes there are very few, or even only 1 sample with a particular category in a feature. When we split the data, that sample could possibly end up in the testing set. \n",
    "# This would be analogous to a deployed production model encountering a category it had never seen before. \n",
    "# Should a column already exist for that category? We have no way of knowing (in theory) what these unseen categories might be, so we cannot create new columns for them.\n",
    "# OneHotEncoder should only be used to create columns for categories that appear in the training data.\n",
    "\n",
    "# Can't the encoded testing dataframes have a column for the new category, even if the training dataframes do not? NO!\n",
    "# Later on we will be fitting models on our training data. Those models will only be able to make predictions on data with the SAME number of features as the data they were trained on. \n",
    "# If we try to use them to make a prediction on testing data that has a different number of columns, the models will throw an error. \n",
    "# This is why we pass the argument 'handle_unknown='ignore' when instantiating the one-hot-encoder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
