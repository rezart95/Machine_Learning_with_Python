{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary:\n",
    "# • Bias: How well or poorly a model is able to predict a target using features. A low bias is better.\n",
    "# • Underfitting: Another word for bias. An underfit model makes poor predictions on both a training and testing set.\n",
    "# • Variance: How much a model’s predictive power will vary using different datasets. A low variance is better.\n",
    "# • Overfitting: Another name for variance. An overfit model makes good predictions on a training set, but poor predictions on a testing set.\n",
    "# • Noise: Natural randomness in data.\n",
    "# • Signal: The true function of features to a target.\n",
    "\n",
    "\n",
    "# The assumption of all predictive models is that there is a relationship between features (X) and target (y). This is called the signal.\n",
    "# A model tries to find that signal.\n",
    "# However, there is also noise in data. This is randomness caused by factors other than the features in our data. .\n",
    "# This noise is considered irreducible because it is not part of the true signal. \n",
    "# Perhaps if our features included all information in the universe, we could eliminate noise. \n",
    "# However, in reality, a real world dataset will always have irreducible noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causes of Underfitting\n",
    "# 1. A model that is too simple (see graphic above).\n",
    "# 2. Not enough data.\n",
    "# 3. Features that do not correlate well with the target.\n",
    "# For instance, if you were to create a decision tree model with a max depth of 2 (a simple model) to predict the temperature tomorrow using today’s\n",
    "# stock prices (features do not correlate with target) and a training set of 5 samples (not enough data), your model would most certainly have high bias.\n",
    "# Notice in the graphic above that a high bias model has not found the signal and has a high error on most data.\n",
    "\n",
    "# Reducing Bias:\n",
    "# You can combat bias by:\n",
    "# 1. Increasing the complexity of your model\n",
    "# 2. Adding more data\n",
    "# 3. Adding features with higher correlation to the target.\n",
    "\n",
    "\n",
    "\n",
    "# Identifying Overfitting\n",
    "# Perhaps the R2 score on the training data is .90 and the R2 score on the testing data is only .5. Or, perhaps the RMSE on the training data is much\n",
    "# lower than RMSE on the testing data.\n",
    "\n",
    "# Causes of Overfitting:\n",
    "# 1. Too complex of a model (see graphic above).\n",
    "# 2. Not enough data\n",
    "# 3. Training data that is not a representative sample of the population, all new data the model might encounter.\n",
    "# Notice in the graphic above that the model has fit on each and every data point. It has fit on the noise in the data rather than the signal.\n",
    "\n",
    "# Combatting Overfitting\n",
    "# 1. Decrease the complexity of the model\n",
    "# 2. Add regularization (you will learn more about this in another lesson)\n",
    "# 3. Add more data to the training set\n",
    "# 4. Ensure that the training set is a representative subset of all data the model will encounter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both Bias and Variance are Bad!\n",
    "# In your work as a machine learning engineer, you will be striving to balance and decrease both bias and variance. An ideal model makes low-error\n",
    "# predictions with both the testing and training data. High bias means your model has not found the signal and high variance means there might be a\n",
    "# model that can perform better on the testing data.\n",
    "\n",
    "# Important Note!\n",
    "# The most important thing to pay attention to in choosing a model is the performance on the testing data.\n",
    "# A high variance model that performs better on testing data is better than a low variance model that performs worse on the testing data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
