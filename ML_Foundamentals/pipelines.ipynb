{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a Pipeline in Machine Learning?\n",
    "\n",
    "# A pipeline contains multiple transformers (or even models!) and performs operations on data IN SEQUENCE. Compare this to ColumnTransformers that perform operations on data IN PARALLEL. When a\n",
    "# pipeline is fit on data, all of the transformers inside it are fit. When data is transformed using a pipeline, the data is transformed by the first transformer first, the second transformer second, etc. A pipeline\n",
    "# can contain any number of transformers as long as they have .fit() and .transform() methods. These are called 'steps'.\n",
    "# If needed, one single estimator, or model, can be placed at the end of a pipeline. You will learn more about that later.\n",
    "# The important thing to remember is that pipelines are ordered, so the order you use to build them matters.\n",
    "# Pipelines can even contain ColumnTransformer AND ColumnTransformers can contain pipelines. You will learn how to do this in a later lesson.\n",
    "\n",
    "\n",
    "\n",
    "# Why Should I Use Pipelines for Machine Learning?\n",
    "\n",
    "# Reasons to use pipelines:\n",
    "# 1. Pipelines use less code than doing each transformer individually. Since each transformer is fit in a single .fit() call, and the data is transformed by all of the transformers in the pipeline in a single\n",
    "# .transform() call, pipelines use significantly less code.\n",
    "# 2. Pipelines make your preprocessing workflow easier to understand. By reducing the code and displaying a diagram of the pipeline you can show your readers clearly how your data is being\n",
    "# transformed before modeling.\n",
    "# 3. Pipelines are easy to use in production models. When you are ready to deploy your model to use in new data, a preprocessing pipeline can ensure that new data can be quickly and easily\n",
    "# preprocessed for modeling.\n",
    "# 4. Pipelines can prevent data leakage. Pipelines are designed to only be fit on training data. Later you will learn a technique called 'cross-validation' and pipelines will simplify performing this without\n",
    "# leaking data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "path = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQG5QTgHn7O1FaenQgpiHadFAza6cfG-cXznWh9a_Z-QWsbsrv3iJ5MpDdSSKTK7ZpTpRosOkK_LR_E/pub?output=csv'\n",
    "df = pd.read_csv(path, index_col='CountryYear')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
