{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab:  \n",
    " Node: one unit that processes incoming information and produces a single output number  \n",
    " Layer: a collection of nodes working in parallel  \n",
    " Input Layer: the first set of nodes that work on the features of the input sample  \n",
    " Output Layer: the last set of nodes that output a prediction  \n",
    " Forward Propagation: the processing and passing of information forward through all layers to produce an output prediction  \n",
    " Cost Function: the difference between the predictions of all samples and their true labels  \n",
    " Backward Propagation: the process of updating the weights of each node to reduce the cost function  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "Sequential models pass information from one layer of nodes to the next some number of times until they produce an output. These are\n",
    "also sometimes called feed-forward networks.\n",
    "There are many kinds of sequential networks that pass information through different kinds of layers. What makes them sequential is\n",
    "that information is passed and transformed in one direction from input ultimately to output. This is called forward propagation.\n",
    "The first kind of model we will learn about is called a densely connected network, or dense network. In a dense network each node in\n",
    "one layer passes its output to all nodes in the next layer, as is visualized below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "One way to think about each node in a dense network is as a separate linear regression model with an additional activation function\n",
    "applied to the output. Actually, you’ve already seen something like this, a logistic regression! A logistic regression is a linear regression\n",
    "model with a sigmoid function applied to the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "Each node applies an activation function to the sum of the products of the inputs and the weights and the bias term. There are a variety\n",
    "of activation functions that a machine learning engineer can try and each layer can have a different activation function. Some examples\n",
    "are: linear, sigmoid, hyperbolic tangent (tanh) and Rectified Linear Unit (ReLU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "A layer is multiple nodes that each learn their own weights and biases to apply to input data. The nodes in a layer work in parallel and\n",
    "do not pass information to each other directly. After applying an activation function chosen by the creator, each node in one layer\n",
    "passes their output to every node in the next layer. The outputs of the previous layer become the inputs to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input layer\n",
    "The nodes in the first layer, called the input layer, each receive a copy of the input data features. Each node has different weights that it\n",
    "applies to each feature and a different bias to add when they are summed. However, each node in a layer uses the same activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layers\n",
    "Between the input layer and the output layer is any number of hidden layers, each with their own collection of nodes. The inputs of each\n",
    "of the nodes in these layers are the outputs of all of the nodes in the previous layer. If the input layer has 10 nodes, each node of the\n",
    "first hidden layer will have 10 weights to apply to the outputs of each of the nodes in the input layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "The output layer is the last set of nodes to be applied. Their output of this layer is the output of the whole network. Because of this, the\n",
    "output layer has a special number of nodes and a special activation function depending on the type of machine learning problem. The\n",
    "number of nodes in the output layer determines how many outputs the network produces and the activation function determines what\n",
    "kind of output the network produces.\n",
    "\n",
    "For example:\n",
    "1. If a single continuous number is the appropriate output, the output layer would have one node and use a linear activation function.\n",
    "2. On the other hand, if two outputs were desired and they should each be a 0 or a 1, the output layer would have two nodes and the\n",
    "activation function would be sigmoid.\n",
    "Easy rules for output layer activation functions:\n",
    "1. Regression: use linear function\n",
    "2. Binary classification: use sigmoid\n",
    "3. Multi-class classification: use softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the Cost Function:\n",
    "In the process of training, or fitting, which is to say finding the correct weights for each node in each layer, the network will attempt to\n",
    "predict a target many times. Each time it performs a forward propagation step and produces an output, that output will be compared to\n",
    "the true label for that sample. The difference between the network output and the true label is the error and the errors of all samples is\n",
    "called the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward propagation\n",
    "Once predictions have been made on one or more samples the errors, collectively called the cost function, are then used to update the\n",
    "weights in each layer to prepare for the next forward propagation step. The process of updating the weights is called the backward\n",
    "propagation step. Backward propagation tries to reduce the cost function to produce more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch\n",
    "The process of completing one forward propagation step on each sample in the training set and updating the weights of each node with\n",
    "backward propagation called an Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "Forward propagation is the process of inputting the features of a sample to an input layer and propagating information forward through\n",
    "some number of layers which each process the information in some way. The forward propagation ends with an output from an output\n",
    "layer. A Neural network performs a defined number of forward and backward propagation steps in order to find the best weights for\n",
    "each node in the network in order to make accurate predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
